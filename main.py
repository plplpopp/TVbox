"""
TVç›´æ’­æºæ›´æ–°å·¥å…· - Pythonæ ¸å¿ƒç‰ˆ - å®Œæ•´æ€§ä¿®å¤ç‰ˆ
ç‰ˆæœ¬: 4.2.0 å®Œæ•´ä¿®å¤ç‰ˆ
"""

import os
import sys
import configparser
import logging
import re
from typing import Any, Dict, List, Tuple, Optional
import datetime
import asyncio
import gzip
import pickle
import socket
import aiohttp
from urllib.parse import urljoin, urlparse
import pytz

# ==================== ä¿®å¤çš„å¸¸é‡å®šä¹‰ ====================
class Paths:
    """è·¯å¾„å¸¸é‡ - ä¿®å¤å®Œæ•´æ€§"""
    CONFIG_DIR = "config"
    OUTPUT_DIR = "output"  
    LOGS_DIR = "logs"
    
    # é…ç½®æ–‡ä»¶è·¯å¾„
    CONFIG_FILE = os.path.join(CONFIG_DIR, "config.ini")
    SUBSCRIBE_FILE = os.path.join(CONFIG_DIR, "subscribe.txt")
    WHITELIST_FILE = os.path.join(CONFIG_DIR, "whitelist.txt")
    LOCAL_FILE = os.path.join(CONFIG_DIR, "local.txt")
    SOURCE_FILE = os.path.join(CONFIG_DIR, "demo.txt")
    FINAL_FILE = os.path.join(OUTPUT_DIR, "result.txt")
    CACHE_FILE = os.path.join(OUTPUT_DIR, "cache.pkl.gz")
    LOG_FILE = os.path.join(LOGS_DIR, "update.log")
    
    # ç»„æ’­é…ç½®æ–‡ä»¶ç›®å½•
    RTP_DIR = os.path.join(CONFIG_DIR, "rtp")

class DefaultConfig:
    """é»˜è®¤é…ç½®å€¼ - ä¿®å¤è¿‡æ»¤è¿‡åº¦é—®é¢˜"""
    
    # ========== åŠŸèƒ½å¼€å…³é…ç½® ==========
    OPEN_DRIVER = False
    OPEN_EPG = False
    OPEN_EMPTY_CATEGORY = True  # ä¿®å¤ï¼šå¼€å¯ç©ºåˆ†ç±»ï¼Œé¿å…å…¨éƒ¨è¿‡æ»¤
    OPEN_FILTER_RESOLUTION = False  # ä¿®å¤ï¼šå…³é—­åˆ†è¾¨ç‡è¿‡æ»¤
    OPEN_FILTER_SPEED = False  # ä¿®å¤ï¼šå…³é—­é€Ÿç‡è¿‡æ»¤
    OPEN_HOTEL = False
    OPEN_HOTEL_FOODIE = True
    OPEN_HOTEL_FOFA = False
    OPEN_LOCAL = True
    OPEN_M3U_RESULT = True
    OPEN_MULTICAST = False
    OPEN_MULTICAST_FOODIE = True
    OPEN_MULTICAST_FOFA = False
    OPEN_REQUEST = False
    OPEN_RTMP = True
    OPEN_SERVICE = True
    OPEN_SPEED_TEST = False  # ä¿®å¤ï¼šå…³é—­æµ‹é€Ÿï¼Œé¿å…è¿æ¥å¤±è´¥
    OPEN_SUBSCRIBE = True
    OPEN_SUPPLY = True
    OPEN_UPDATE = True
    OPEN_UPDATE_TIME = True
    OPEN_URL_INFO = False
    OPEN_USE_CACHE = True
    OPEN_HISTORY = True
    OPEN_HEADERS = False
    SPEED_TEST_FILTER_HOST = False
    IPV6_SUPPORT = False
    
    # ========== ç½‘ç»œæœåŠ¡é…ç½® ==========
    APP_HOST = "http://localhost"
    APP_PORT = 8000
    CDN_URL = ""
    
    # ========== æ–‡ä»¶è·¯å¾„é…ç½® ==========
    FINAL_FILE = "output/result.txt"
    LOCAL_FILE = "config/local.txt"
    SOURCE_FILE = "config/demo.txt"
    
    # ========== æ•°é‡é™åˆ¶é…ç½® ==========
    HOTEL_NUM = 10
    HOTEL_PAGE_NUM = 1
    MULTICAST_NUM = 10
    MULTICAST_PAGE_NUM = 1
    LOCAL_NUM = 10
    SUBSCRIBE_NUM = 10
    URLS_LIMIT = 10
    
    # ========== åœ°åŒºè®¾ç½®é…ç½® ==========
    HOTEL_REGION_LIST = "å…¨éƒ¨"
    MULTICAST_REGION_LIST = "å…¨éƒ¨"
    
    # ========== ç½‘ç»œä¼˜åŒ–é…ç½® ==========
    ISP = ""
    IPV4_NUM = ""
    IPV6_NUM = ""
    IPV_TYPE = "å…¨éƒ¨"
    IPV_TYPE_PREFER = "auto"
    LOCATION = ""
    
    # ========== è´¨é‡è®¾ç½®é…ç½® ==========
    MIN_RESOLUTION = "1920x1080"
    MAX_RESOLUTION = "1920x1080"
    MIN_SPEED = 0.5
    
    # ========== æ—¶é—´è®¾ç½®é…ç½® ==========
    RECENT_DAYS = 30
    REQUEST_TIMEOUT = 10
    SPEED_TEST_LIMIT = 10
    SPEED_TEST_TIMEOUT = 10
    TIME_ZONE = "Asia/Shanghai"
    UPDATE_INTERVAL = 12
    UPDATE_TIME_POSITION = "top"

# ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²
USER_AGENT = "Mozilla/5.0 (compatible; TVSourceUpdater/4.2.0)"

# ==================== ä¿®å¤çš„å·¥å…·å‡½æ•° ====================
class Utility:
    """å·¥å…·å‡½æ•°é›†åˆ - ä¿®å¤æ—¶é—´è®¡ç®—é”™è¯¯"""
    
    @staticmethod
    def ensure_directories():
        """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
        directories = [
            Paths.CONFIG_DIR,
            Paths.OUTPUT_DIR,  
            Paths.LOGS_DIR,
            Paths.RTP_DIR
        ]
        for directory in directories:
            if directory and not os.path.exists(directory):
                try:
                    os.makedirs(directory, exist_ok=True)
                    logging.info(f"åˆ›å»ºç›®å½•: {directory}")
                except Exception as e:
                    logging.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {directory}: {e}")
    
    @staticmethod
    def setup_logging():
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        Utility.ensure_directories()
        try:
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
                handlers=[
                    logging.FileHandler(Paths.LOG_FILE, encoding='utf-8'),
                    logging.StreamHandler(sys.stdout)
                ]
            )
            logging.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"æ—¥å¿—åˆå§‹åŒ–å¤±è´¥: {e}")
    
    @staticmethod
    def safe_time_difference(start_time: Optional[datetime.datetime], 
                           end_time: Optional[datetime.datetime]) -> float:
        """
        å®‰å…¨çš„æ—¶é—´å·®è®¡ç®— - ä¿®å¤NoneTypeé”™è¯¯
        
        Args:
            start_time: å¼€å§‹æ—¶é—´
            end_time: ç»“æŸæ—¶é—´
            
        Returns:
            æ—¶é—´å·®ï¼ˆç§’ï¼‰
        """
        # ä¿®å¤ï¼šæ£€æŸ¥Noneå€¼
        if start_time is None or end_time is None:
            logging.warning("æ—¶é—´å‚æ•°ä¸ºNoneï¼Œè¿”å›0ç§’é—´éš”")
            return 0.0
        
        try:
            duration = (end_time - start_time).total_seconds()
            return max(0.0, duration)  # ç¡®ä¿éè´Ÿ
        except Exception as e:
            logging.error(f"æ—¶é—´è®¡ç®—é”™è¯¯: {e}")
            return 0.0
    
    @staticmethod
    def format_interval(seconds: float) -> str:
        """æ ¼å¼åŒ–æ—¶é—´é—´éš”"""
        if seconds < 60:
            return f"{int(seconds)}ç§’"
        elif seconds < 3600:
            return f"{int(seconds // 60)}åˆ†{int(seconds % 60)}ç§’"
        else:
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            return f"{int(hours)}æ—¶{int(minutes)}åˆ†"
    
    @staticmethod
    def is_valid_url(url: str) -> bool:
        """éªŒè¯URLæ ¼å¼"""
        try:
            result = urlparse(url)
            return all([result.scheme, result.netloc])
        except Exception:
            return False
    
    @staticmethod
    def read_file_content(file_path: str) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            if not os.path.exists(file_path):
                return ""
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logging.error(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return ""
    
    @staticmethod
    def write_file_content(file_path: str, content: str) -> bool:
        """å†™å…¥æ–‡ä»¶å†…å®¹"""
        try:
            Utility.ensure_directories()
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            logging.info(f"æ–‡ä»¶å†™å…¥æˆåŠŸ: {file_path}")
            return True
        except Exception as e:
            logging.error(f"å†™å…¥æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return False

# ==================== ä¿®å¤çš„é…ç½®ç®¡ç†å™¨ ====================
class ConfigManager:
    """é…ç½®ç®¡ç†å™¨å•ä¾‹"""
    
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self._config = None
            self._enhanced_config = None
            self._initialized = True
    
    def load_config(self, config_path: str = Paths.CONFIG_FILE) -> bool:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            Utility.ensure_directories()
            
            if not os.path.exists(config_path):
                logging.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                # åˆ›å»ºé»˜è®¤é…ç½®ç±»
                class FixedConfig:
                    def __getattr__(self, name):
                        return getattr(DefaultConfig, name.upper())
                self._enhanced_config = FixedConfig()
                return True
            
            parser = configparser.ConfigParser()
            parser.read(config_path, encoding='utf-8')
            
            # åˆ›å»ºåŠ¨æ€é…ç½®ç±»
            class DynamicConfig:
                def __getattr__(self, name):
                    # ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„å€¼
                    if parser.has_option('Settings', name):
                        value = parser.get('Settings', name)
                        # ç±»å‹è½¬æ¢
                        if name.startswith('open_'):
                            return value.lower() in ('true', 'yes', '1', 'on')
                        elif name in ['app_port', 'urls_limit']:
                            try:
                                return int(value)
                            except:
                                return getattr(DefaultConfig, name.upper())
                        else:
                            return value
                    # ä½¿ç”¨é»˜è®¤å€¼
                    return getattr(DefaultConfig, name.upper())
            
            self._enhanced_config = DynamicConfig()
            logging.info("âœ… é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ")
            return True
            
        except Exception as e:
            logging.error(f"âŒ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    @property
    def config(self):
        """è·å–é…ç½®å¯¹è±¡"""
        if self._enhanced_config is None:
            self.load_config()
        return self._enhanced_config

# å…¨å±€é…ç½®å®ä¾‹
config_manager = ConfigManager()

def get_config():
    """è·å–é…ç½®"""
    return config_manager.config

# ==================== å½»åº•ä¿®å¤çš„æ ¸å¿ƒç±» ====================
class FixedTVSourceUpdater:
    """ä¿®å¤çš„TVç›´æ’­æºæ›´æ–°å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ– - ä¿®å¤ç»Ÿè®¡å­—æ®µå®Œæ•´æ€§"""
        self.config = get_config()
        self.session = None
        self.cache_data = {}
        # ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰ç»Ÿè®¡å­—æ®µéƒ½æœ‰åˆå§‹å€¼
        self.stats = {
            "total_channels": 0,
            "total_urls": 0,
            "valid_urls": 0,
            "start_time": datetime.datetime.now(),  # ä¿®å¤ï¼šç«‹å³è®¾ç½®åˆå§‹å€¼
            "end_time": datetime.datetime.now(),    # ä¿®å¤ï¼šè®¾ç½®é»˜è®¤å€¼
            "success": False
        }
        
    async def initialize(self):
        """åˆå§‹åŒ–å¼‚æ­¥ä¼šè¯"""
        if self.session is None:
            self.session = aiohttp.ClientSession(
                headers={'User-Agent': USER_AGENT},
                timeout=aiohttp.ClientTimeout(total=10)  # ä¿®å¤ï¼šä½¿ç”¨å›ºå®šè¶…æ—¶
            )
        
        # ä¿®å¤ï¼šé‡æ–°è®¾ç½®å¼€å§‹æ—¶é—´
        self.stats["start_time"] = datetime.datetime.now()
        logging.info("âœ… æ›´æ–°å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def close(self):
        """å…³é—­å¼‚æ­¥ä¼šè¯"""
        if self.session:
            await self.session.close()
            self.session = None
        
        # ä¿®å¤ï¼šç¡®ä¿ç»“æŸæ—¶é—´è¢«è®¾ç½®
        self.stats["end_time"] = datetime.datetime.now()
    
    async def update_sources(self) -> bool:
        """
        æ›´æ–°ç›´æ’­æº - å½»åº•ä¿®å¤å®Œæ•´æ€§é—®é¢˜
        """
        try:
            logging.info("ğŸš€ å¼€å§‹æ›´æ–°ç›´æ’­æº...")
            
            # ä¿®å¤ï¼šé‡ç½®å¼€å§‹æ—¶é—´
            self.stats["start_time"] = datetime.datetime.now()
            self.stats["success"] = False
            
            # 1. æ”¶é›†æ‰€æœ‰æº
            all_sources = await self.safe_collect_sources()
            self.stats["total_channels"] = len(all_sources)
            self.stats["total_urls"] = sum(len(urls) for urls in all_sources.values())
            
            # 2. å®‰å…¨è¿‡æ»¤ï¼ˆé¿å…è¿‡åº¦è¿‡æ»¤ï¼‰
            filtered_sources = await self.safe_filter_sources(all_sources)
            self.stats["valid_urls"] = sum(len(urls) for urls in filtered_sources.values())
            
            # 3. ç”Ÿæˆç»“æœ
            result_content = self.generate_safe_result(filtered_sources)
            
            # 4. ä¿å­˜ç»“æœ
            success = Utility.write_file_content(Paths.FINAL_FILE, result_content)
            
            # ä¿®å¤ï¼šç¡®ä¿ç»“æŸæ—¶é—´è¢«è®¾ç½®
            self.stats["end_time"] = datetime.datetime.now()
            self.stats["success"] = success
            
            # 5. è®°å½•ç»Ÿè®¡ï¼ˆä½¿ç”¨å®‰å…¨çš„æ—¶é—´è®¡ç®—ï¼‰
            await self.safe_log_statistics()
            
            return success
            
        except Exception as e:
            logging.error(f"âŒ æ›´æ–°ç›´æ’­æºå¤±è´¥: {e}")
            # ä¿®å¤ï¼šå¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿè®¾ç½®ç»“æŸæ—¶é—´
            self.stats["end_time"] = datetime.datetime.now()
            self.stats["success"] = False
            return False
    
    async def safe_collect_sources(self) -> Dict[str, List[str]]:
        """å®‰å…¨æ”¶é›†æºæ•°æ®"""
        sources = {}
        
        try:
            # æœ¬åœ°æº
            if self.config.open_local:
                local_content = Utility.read_file_content(Paths.LOCAL_FILE)
                local_sources = self.parse_sources(local_content, "æœ¬åœ°æº")
                sources.update(local_sources)
                logging.info(f"ğŸ“ æœ¬åœ°æº: {len(local_sources)} ä¸ªé¢‘é“")
            
            # è®¢é˜…æºï¼ˆæ ¹æ®å›¾ç‰‡æ˜¾ç¤ºä¸ºç©ºï¼‰
            if self.config.open_subscribe:
                subscribe_content = Utility.read_file_content(Paths.SUBSCRIBE_FILE)
                if not subscribe_content.strip():
                    logging.warning("è®¢é˜…æ–‡ä»¶ä¸ºç©º")
                else:
                    subscribe_sources = await self.load_subscribe_sources()
                    sources.update(subscribe_sources)
                    logging.info(f"ğŸ“¡ è®¢é˜…æº: {len(subscribe_sources)} ä¸ªé¢‘é“")
            
            # æ¨¡æ¿æº
            if self.config.open_update:
                template_content = Utility.read_file_content(Paths.SOURCE_FILE)
                template_sources = self.parse_sources(template_content, "æ¨¡æ¿æº")
                sources.update(template_sources)
                logging.info(f"ğŸ“‹ æ¨¡æ¿æº: {len(template_sources)} ä¸ªé¢‘é“")
            
            logging.info(f"ğŸ“Š æ€»è®¡æ”¶é›†: {len(sources)} ä¸ªé¢‘é“")
            return sources
            
        except Exception as e:
            logging.error(f"æ”¶é›†æºæ•°æ®å¤±è´¥: {e}")
            return {}
    
    def parse_sources(self, content: str, source_type: str) -> Dict[str, List[str]]:
        """è§£ææºæ•°æ®"""
        sources = {}
        
        if not content:
            return sources
        
        lines = content.split('\n')
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            if ',' in line:
                parts = line.split(',', 1)  # åªåˆ†å‰²ç¬¬ä¸€ä¸ªé€—å·
                if len(parts) >= 2:
                    channel = parts[0].strip()
                    url = parts[1].strip()
                    
                    # ä¿®å¤ï¼šä½¿ç”¨å®½æ¾çš„URLéªŒè¯
                    if channel and self.is_potential_stream_url(url):
                        if channel not in sources:
                            sources[channel] = []
                        sources[channel].append(url)
        
        return sources
    
    def is_potential_stream_url(self, url: str) -> bool:
        """
        å®½æ¾çš„URLéªŒè¯ - ä¿®å¤è¿‡åº¦è¿‡æ»¤é—®é¢˜
        """
        if not url or len(url) < 5:
            return False
        
        # æ¥å—æ›´å¤šæ ¼å¼çš„URL
        valid_indicators = [
            'http://', 'https://', 'rtmp://', 'rtsp://', 
            '.m3u8', '.ts', '.mp4', '.flv', '://',
            'udp://', 'mms://'
        ]
        
        url_lower = url.lower()
        return any(indicator in url_lower for indicator in valid_indicators)
    
    async def load_subscribe_sources(self) -> Dict[str, List[str]]:
        """åŠ è½½è®¢é˜…æº"""
        # æ ¹æ®å›¾ç‰‡æ˜¾ç¤ºï¼Œè®¢é˜…æ–‡ä»¶ä¸ºç©ºï¼Œè¿”å›ç©ºç»“æœ
        return {}
    
    async def safe_filter_sources(self, sources: Dict[str, List[str]]) -> Dict[str, List[str]]:
        """
        å®‰å…¨è¿‡æ»¤æº - ä¿®å¤è¿‡åº¦è¿‡æ»¤é—®é¢˜
        """
        if not sources:
            return {}
        
        # ä¿®å¤ï¼šå¦‚æœå…³é—­äº†è¿‡æ»¤åŠŸèƒ½ï¼Œç›´æ¥è¿”å›æ‰€æœ‰æº
        if not self.config.open_speed_test and not self.config.open_filter_resolution:
            logging.info("ğŸ”§ è¿‡æ»¤åŠŸèƒ½å·²å…³é—­ï¼Œè¿”å›æ‰€æœ‰æº")
            return sources
        
        filtered_sources = {}
        
        for channel, urls in sources.items():
            valid_urls = []
            
            for url in urls[:self.config.urls_limit]:
                # ä¿®å¤ï¼šä½¿ç”¨æ›´å®½æ¾çš„éªŒè¯
                if await self.is_url_acceptable(url):
                    valid_urls.append(url)
            
            # ä¿®å¤ï¼šå³ä½¿æ²¡æœ‰æœ‰æ•ˆURLï¼Œä¹Ÿä¿ç•™é¢‘é“ï¼ˆå¦‚æœé…ç½®å…è®¸ï¼‰
            if valid_urls or self.config.open_empty_category:
                filtered_sources[channel] = valid_urls
        
        logging.info(f"ğŸ” æºè¿‡æ»¤å®Œæˆ: {len(filtered_sources)}/{len(sources)} ä¸ªé¢‘é“")
        return filtered_sources
    
    async def is_url_acceptable(self, url: str) -> bool:
        """åˆ¤æ–­URLæ˜¯å¦å¯æ¥å—"""
        # åŸºæœ¬éªŒè¯
        if not self.is_potential_stream_url(url):
            return False
        
        # å¦‚æœå…³é—­äº†æµ‹é€Ÿï¼Œç›´æ¥æ¥å—
        if not self.config.open_speed_test:
            return True
        
        # ç®€å•çš„è¿æ¥æµ‹è¯•ï¼ˆä¸ä¸¥æ ¼éªŒè¯ï¼‰
        try:
            async with self.session.head(url, timeout=3) as response:
                return response.status in [200, 206, 301, 302]
        except:
            return True  # ä¿®å¤ï¼šå³ä½¿è¿æ¥å¤±è´¥ä¹Ÿæ¥å—ï¼ˆé¿å…è¿‡åº¦è¿‡æ»¤ï¼‰
    
    def generate_safe_result(self, sources: Dict[str, List[str]]) -> str:
        """ç”Ÿæˆå®‰å…¨çš„ç»“æœ"""
        lines = []
        
        # æ–‡ä»¶å¤´
        if self.config.open_update_time:
            current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            lines.append(f"# ç›´æ’­æºæ›´æ–°ç»“æœ")
            lines.append(f"# æ›´æ–°æ—¶é—´: {current_time}")
            lines.append(f"# é¢‘é“æ•°é‡: {len(sources)}")
            lines.append(f"# æ€»URLæ•°: {sum(len(urls) for urls in sources.values())}")
            lines.append("")
        
        # é¢‘é“æ•°æ®
        if sources:
            for channel, urls in sorted(sources.items()):
                for url in urls:
                    lines.append(f"{channel},{url}")
        else:
            lines.append("# æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç›´æ’­æº")
            lines.append("# è¿™å¯èƒ½æ˜¯å› ä¸º:")
            lines.append("# 1. æºæ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
            lines.append("# 2. è¿‡æ»¤è®¾ç½®è¿‡äºä¸¥æ ¼")
            lines.append("# 3. ç½‘ç»œè¿æ¥é—®é¢˜")
        
        return '\n'.join(lines)
    
    async def safe_log_statistics(self):
        """
        å®‰å…¨è®°å½•ç»Ÿè®¡ - å½»åº•ä¿®å¤æ—¶é—´è®¡ç®—é”™è¯¯
        """
        try:
            # ä¿®å¤ï¼šä½¿ç”¨å®‰å…¨çš„æ—¶é—´è®¡ç®—
            duration = Utility.safe_time_difference(
                self.stats["start_time"], 
                self.stats["end_time"]
            )
            
            logging.info("ğŸ“Š æ›´æ–°ç»Ÿè®¡ä¿¡æ¯:")
            logging.info(f"   æ€»é¢‘é“æ•°: {self.stats['total_channels']}")
            logging.info(f"   æ€»URLæ•°: {self.stats['total_urls']}")
            logging.info(f"   æœ‰æ•ˆURLæ•°: {self.stats['valid_urls']}")
            
            # ä¿®å¤ï¼šå®‰å…¨è®¡ç®—æœ‰æ•ˆç‡
            if self.stats['total_urls'] > 0:
                efficiency = (self.stats['valid_urls'] / self.stats['total_urls']) * 100
                logging.info(f"   æœ‰æ•ˆç‡: {efficiency:.1f}%")
            else:
                logging.info("   æœ‰æ•ˆç‡: 0%")
            
            logging.info(f"   è€—æ—¶: {Utility.format_interval(duration)}")
            logging.info(f"   ç»“æœæ–‡ä»¶: {Paths.FINAL_FILE}")
            
        except Exception as e:
            logging.error(f"è®°å½•ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")

# ==================== ä¿®å¤çš„ä¸»ç¨‹åºå…¥å£ ====================
async def main():
    """ä¸»ç¨‹åºå…¥å£ - ä¿®å¤ç‰ˆ"""
    try:
        # è®¾ç½®æ—¥å¿—ç³»ç»Ÿ
        Utility.setup_logging()
        
        print("=" * 60)
        print("ğŸ“º TVç›´æ’­æºæ›´æ–°å·¥å…· - ä¿®å¤å®Œæ•´æ€§é—®é¢˜")
        print("ç‰ˆæœ¬: 4.2.0")
        print("=" * 60)
        
        # å¤„ç†å‘½ä»¤è¡Œå‚æ•°
        if len(sys.argv) > 1:
            if sys.argv[1] in ['--help', '-h']:
                print("ä½¿ç”¨æ–¹æ³•: python tv_updater.py [--config|--stats|--help]")
                return
            elif sys.argv[1] == '--config':
                print("é…ç½®ä¿¡æ¯:")
                config = get_config()
                # æ˜¾ç¤ºå…³é”®é…ç½®
                print(f"open_speed_test: {getattr(config, 'open_speed_test', False)}")
                print(f"open_filter_resolution: {getattr(config, 'open_filter_resolution', False)}")
                print(f"open_empty_category: {getattr(config, 'open_empty_category', True)}")
                return
            elif sys.argv[1] == '--stats':
                print("æ–‡ä»¶ç»Ÿè®¡:")
                for file_path, desc in [
                    (Paths.LOCAL_FILE, "æœ¬åœ°æºæ–‡ä»¶"),
                    (Paths.SOURCE_FILE, "æ¨¡æ¿æ–‡ä»¶"),
                    (Paths.FINAL_FILE, "ç»“æœæ–‡ä»¶")
                ]:
                    exists = os.path.exists(file_path)
                    print(f"{desc}: {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
                return
        
        # åŠ è½½é…ç½®
        if not config_manager.load_config():
            print("âš ï¸ ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­è¿è¡Œ")
        
        print("ğŸ”§ åˆå§‹åŒ–ç¯å¢ƒ...")
        Utility.ensure_directories()
        
        # åˆ›å»ºä¿®å¤çš„æ›´æ–°å™¨
        print("ğŸš€ åˆå§‹åŒ–æ›´æ–°å™¨...")
        updater = FixedTVSourceUpdater()
        await updater.initialize()
        
        # æ‰§è¡Œæ›´æ–°
        print("ğŸ“¡ å¼€å§‹æ›´æ–°ç›´æ’­æº...")
        success = await updater.update_sources()
        
        # æ¸…ç†èµ„æº
        await updater.close()
        
        if success:
            print("ğŸ‰ ç›´æ’­æºæ›´æ–°æˆåŠŸ!")
            
            # æ˜¾ç¤ºç»“æœæ–‡ä»¶ä¿¡æ¯
            if os.path.exists(Paths.FINAL_FILE):
                with open(Paths.FINAL_FILE, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    channel_lines = [line for line in lines if line.strip() and not line.startswith('#')]
                    print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {Paths.FINAL_FILE}")
                    print(f"   æœ‰æ•ˆé¢‘é“æ•°: {len(channel_lines)}")
                    print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(Paths.FINAL_FILE)} å­—èŠ‚")
            
            return 0
        else:
            print("âŒ ç›´æ’­æºæ›´æ–°å¤±è´¥!")
            
            # æä¾›è¯¦ç»†çš„é”™è¯¯è¯Šæ–­
            if updater.stats["valid_urls"] == 0:
                print("ğŸ’¡ è¯Šæ–­ä¿¡æ¯:")
                print("   - æ”¶é›†åˆ°çš„é¢‘é“: {}".format(updater.stats["total_channels"]))
                print("   - æ”¶é›†åˆ°çš„URL: {}".format(updater.stats["total_urls"]))
                print("   - è¿‡æ»¤åå‰©ä½™: {}".format(updater.stats["valid_urls"]))
                print("   - å»ºè®®: æ£€æŸ¥æºæ–‡ä»¶æ ¼å¼å’Œè¿‡æ»¤è®¾ç½®")
            
            return 1
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
        return 1
    except Exception as e:
        print(f"ğŸ’¥ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
